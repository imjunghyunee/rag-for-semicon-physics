from __future__ import annotations
from typing import List, Dict, Any, Optional
from rag_pipeline import utils, retrievers, config
from langchain.schema import Document
import json


class PlanExecuteAgent:
    """Plan and Execute Agent for complex multi-hop questions"""
    
    def __init__(self, max_steps: int = 5):
        self.max_steps = max_steps
        
    def create_plan(self, query: str, context_so_far: str = "") -> Dict[str, Any]:
        """
        ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
        
        Args:
            query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
            context_so_far: ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ëœ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ê³„íš ì •ë³´ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            response = utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert in semiconductor physics who excels at creating step-by-step plans to solve complex problems.

                        When given a complex question, create a detailed plan with specific, actionable steps that:
                        1. Break down the problem into logical components
                        2. Identify what specific information needs to be retrieved (concepts, formulas, data)
                        3. Determine the sequence of steps needed to solve the problem
                        4. Each step should be specific and focused on retrieving or analyzing particular information

                        Format your response as a JSON object with this structure:
                        {
                            "overall_goal": "What we're trying to achieve",
                            "current_step": 1,
                            "steps": [
                                {
                                    "step_number": 1,
                                    "action": "retrieve_concept|retrieve_formula|retrieve_data|analyze|calculate",
                                    "description": "What specifically to do in this step",
                                    "search_query": "Specific query to search for information",
                                    "expected_outcome": "What information we expect to get"
                                }
                            ],
                            "success_criteria": "How we'll know when the problem is solved"
                        }

                        Available actions:
                        - retrieve_concept: Search for fundamental concepts or definitions
                        - retrieve_formula: Search for specific equations or formulas
                        - retrieve_data: Search for numerical values, parameters, or experimental data
                        - analyze: Analyze gathered information to draw conclusions
                        - calculate: Perform calculations using gathered formulas and data

                        Respond with ONLY the JSON object."""
                    },
                    {
                        "role": "user",
                        "content": f"""Complex Question: {query}

                        Context gathered so far:
                        {context_so_far if context_so_far else "None"}

                        Create a detailed plan to solve this semiconductor physics problem."""
                    }
                ],
                max_tokens=1500,
                temperature=0.2,
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                plan = json.loads(response_text)
                return plan
            except json.JSONDecodeError:
                print(f"Failed to parse plan JSON: {response_text}")
                # í´ë°± ê³„íš
                return self._create_fallback_plan(query)
                
        except Exception as e:
            print(f"Error creating plan: {e}")
            return self._create_fallback_plan(query)
    
    def _create_fallback_plan(self, query: str) -> Dict[str, Any]:
        """Create a simple fallback plan when main planning fails"""
        return {
            "overall_goal": f"Solve the complex question: {query}",
            "current_step": 1,
            "steps": [
                {
                    "step_number": 1,
                    "action": "retrieve_concept",
                    "description": "Gather fundamental concepts related to the question",
                    "search_query": f"fundamental concepts related to: {query}",
                    "expected_outcome": "Basic understanding of relevant concepts"
                },
                {
                    "step_number": 2,
                    "action": "retrieve_formula",
                    "description": "Find relevant formulas and equations",
                    "search_query": f"formulas equations for: {query}",
                    "expected_outcome": "Mathematical relationships needed"
                },
                {
                    "step_number": 3,
                    "action": "analyze",
                    "description": "Analyze gathered information to solve the problem",
                    "search_query": "",
                    "expected_outcome": "Solution to the original question"
                }
            ],
            "success_criteria": "All aspects of the question are addressed with supporting evidence"
        }
    
    def execute_step(
        self, 
        step: Dict[str, Any], 
        retrieval_type: str = None, 
        hybrid_weights: List[float] = None
    ) -> Dict[str, Any]:
        """
        ê³„íšì˜ ë‹¨ì¼ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            step: ì‹¤í–‰í•  ë‹¨ê³„ ì •ë³´
            retrieval_type: ê²€ìƒ‰ íƒ€ì…
            hybrid_weights: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            
        Returns:
            ì‹¤í–‰ ê²°ê³¼
        """
        action = step.get("action", "retrieve_concept")
        search_query = step.get("search_query", "")
        description = step.get("description", "")
        
        print(f"Executing step {step.get('step_number', '?')}: {action}")
        print(f"Description: {description}")
        print(f"Search query: {search_query}")
        
        if action in ["retrieve_concept", "retrieve_formula", "retrieve_data"] and search_query:
            # ì •ë³´ ê²€ìƒ‰ ë‹¨ê³„
            try:
                context_docs = self._perform_retrieval(search_query, retrieval_type, hybrid_weights)
                
                context_contents = [
                    doc.page_content for doc in context_docs if isinstance(doc, Document)
                ]
                context_str = "\n\n---\n\n".join(context_contents)
                
                # ê²€ìƒ‰ëœ ì •ë³´ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
                if context_str.strip():
                    summary = self._summarize_retrieved_info(search_query, context_str, action)
                else:
                    summary = f"No relevant information found for: {search_query}"
                
                return {
                    "step_number": step.get("step_number"),
                    "action": action,
                    "search_query": search_query,
                    "context": context_str,
                    "summary": summary,
                    "context_docs": context_docs,
                    "success": bool(context_str.strip())
                }
                
            except Exception as e:
                print(f"Error in retrieval step: {e}")
                return {
                    "step_number": step.get("step_number"),
                    "action": action,
                    "search_query": search_query,
                    "context": "",
                    "summary": f"Error retrieving information: {str(e)}",
                    "context_docs": [],
                    "success": False
                }
        
        elif action in ["analyze", "calculate"]:
            # ë¶„ì„/ê³„ì‚° ë‹¨ê³„ - ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©
            return {
                "step_number": step.get("step_number"),
                "action": action,
                "search_query": "",
                "context": "",
                "summary": f"Analysis/calculation step: {description}",
                "context_docs": [],
                "success": True
            }
        
        else:
            return {
                "step_number": step.get("step_number"),
                "action": action,
                "search_query": search_query,
                "context": "",
                "summary": f"Unknown action or empty search query",
                "context_docs": [],
                "success": False
            }
    
    def _perform_retrieval(
        self, 
        query: str, 
        retrieval_type: str = None, 
        hybrid_weights: List[float] = None
    ) -> List[Document]:
        """ì‹¤ì œ ì •ë³´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if retrieval_type == "hyde" and hybrid_weights:
            context_docs, _ = retrievers.hyde_hybrid_retrieve(query, weights=hybrid_weights)
        elif retrieval_type == "hyde":
            context_docs, _ = retrievers.hyde_retrieve(query)
        elif retrieval_type == "summary" and hybrid_weights:
            context_docs, _ = retrievers.summary_hybrid_retrieve(query, weights=hybrid_weights)
        elif retrieval_type == "summary":
            context_docs, _ = retrievers.summary_retrieve(query)
        elif hybrid_weights:
            context_docs = retrievers.vectordb_hybrid_retrieve(query, weights=hybrid_weights)
        else:
            context_docs = retrievers.vectordb_retrieve(query)
        
        # tupleì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë¬¸ì„œë“¤
        if isinstance(context_docs, tuple):
            context_docs = context_docs[0]
            
        return context_docs
    
    def _summarize_retrieved_info(self, query: str, context: str, action: str) -> str:
        """ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        try:
            response = utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": f"""You are an expert in semiconductor physics. Summarize the retrieved information in a clear, concise way that's relevant to the search query.

                        Action type: {action}
                        - If retrieve_concept: Focus on definitions and fundamental principles
                        - If retrieve_formula: Focus on equations and mathematical relationships  
                        - If retrieve_data: Focus on numerical values and parameters

                        Keep the summary focused and technically accurate."""
                    },
                    {
                        "role": "user",
                        "content": f"""Search Query: {query}

                        Retrieved Information:
                        {context}

                        Provide a concise summary of the key information that's relevant to the search query."""
                    }
                ],
                max_tokens=300,
                temperature=0.2,
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error summarizing retrieved info: {e}")
            return f"Retrieved information for: {query} (summary generation failed)"
    
    def evaluate_progress(
        self, 
        original_query: str, 
        plan: Dict[str, Any], 
        executed_steps: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„ í‰ê°€í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            original_query: ì›ë³¸ ì§ˆë¬¸
            plan: í˜„ì¬ ê³„íš
            executed_steps: ì§€ê¸ˆê¹Œì§€ ì‹¤í–‰ëœ ë‹¨ê³„ë“¤
            
        Returns:
            í‰ê°€ ê²°ê³¼ ë° ë‹¤ìŒ í–‰ë™
        """
        try:
            # ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ ì •ë¦¬
            all_context = []
            all_summaries = []
            
            for step in executed_steps:
                if step.get("context"):
                    all_context.append(f"Step {step['step_number']} ({step['action']}): {step['context']}")
                if step.get("summary"):
                    all_summaries.append(f"Step {step['step_number']}: {step['summary']}")
            
            combined_context = "\n\n".join(all_context)
            combined_summaries = "\n".join(all_summaries)
            
            response = utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert in semiconductor physics who evaluates problem-solving progress.

                        Analyze the progress made so far and determine the next action:

                        1. CONTINUE: If more information is needed, continue with the next planned step
                        2. REPLAN: If the current plan isn't working, create a new plan
                        3. COMPLETE: If enough information has been gathered to answer the original question

                        Respond with a JSON object:
                        {
                            "decision": "CONTINUE|REPLAN|COMPLETE",
                            "reasoning": "Why this decision was made",
                            "confidence": 0.8,
                            "missing_info": ["What information is still needed"],
                            "can_answer": true/false
                        }"""
                    },
                    {
                        "role": "user",
                        "content": f"""Original Question: {original_query}

                        Current Plan Goal: {plan.get('overall_goal', 'Not specified')}
                        Success Criteria: {plan.get('success_criteria', 'Not specified')}

                        Steps Executed So Far:
                        {combined_summaries}

                        Remaining Planned Steps: {len(plan.get('steps', [])) - len(executed_steps)}

                        Evaluate the progress and determine the next action."""
                    }
                ],
                max_tokens=500,
                temperature=0.2,
            )
            
            response_text = response.choices[0].message.content.strip()
            
            try:
                evaluation = json.loads(response_text)
                return evaluation
            except json.JSONDecodeError:
                print(f"Failed to parse evaluation JSON: {response_text}")
                # í´ë°± í‰ê°€
                return {
                    "decision": "CONTINUE" if len(executed_steps) < len(plan.get('steps', [])) else "COMPLETE",
                    "reasoning": "Fallback evaluation due to parsing error",
                    "confidence": 0.5,
                    "missing_info": [],
                    "can_answer": len(executed_steps) >= 2
                }
                
        except Exception as e:
            print(f"Error in progress evaluation: {e}")
            return {
                "decision": "COMPLETE",
                "reasoning": f"Error in evaluation: {str(e)}",
                "confidence": 0.3,
                "missing_info": [],
                "can_answer": True
            }
    
    def generate_final_answer(
        self, 
        original_query: str, 
        executed_steps: List[Dict[str, Any]]
    ) -> str:
        """
        ì‹¤í–‰ëœ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            original_query: ì›ë³¸ ì§ˆë¬¸
            executed_steps: ì‹¤í–‰ëœ ëª¨ë“  ë‹¨ê³„ë“¤
            
        Returns:
            ìµœì¢… ë‹µë³€
        """
        try:
            # ëª¨ë“  ë‹¨ê³„ì˜ ì •ë³´ í†µí•©
            step_summaries = []
            all_context = []
            
            for step in executed_steps:
                step_info = f"Step {step['step_number']} ({step['action']}): {step['summary']}"
                step_summaries.append(step_info)
                
                if step.get("context"):
                    all_context.append(step["context"])
            
            combined_context = "\n\n=== STEP CONTEXT ===\n\n".join(all_context)
            step_summary = "\n".join(step_summaries)
            
            response = utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert in semiconductor physics who provides comprehensive final answers.

                        Based on the step-by-step investigation and gathered information, provide a complete answer that:
                        1. Directly addresses the original question
                        2. Uses the information gathered in each step
                        3. Shows clear reasoning and connections
                        4. Is technically accurate for semiconductor physics
                        5. Includes relevant details, formulas, and explanations

                        Structure your response clearly with proper reasoning."""
                    },
                    {
                        "role": "user",
                        "content": f"""Original Question: {original_query}

                        Investigation Summary:
                        {step_summary}

                        Detailed Information Gathered:
                        {combined_context}

                        Provide a comprehensive final answer to the original question."""
                    }
                ],
                max_tokens=2000,
                temperature=0.2,
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating final answer: {e}")
            # í´ë°±: ë‹¨ê³„ ìš”ì•½ë§Œ ì œê³µ
            step_info = "\n".join([f"Step {s['step_number']}: {s['summary']}" for s in executed_steps])
            return f"Based on the investigation:\n\n{step_info}\n\nError occurred while generating detailed answer: {str(e)}"


def process_complex_query_with_plan_execute(
    original_query: str,
    retrieval_type: str = None,
    hybrid_weights: List[float] = None,
    max_steps: int = 5
) -> Dict[str, Any]:
    """
    Plan and Execute agentë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        original_query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
        retrieval_type: ê²€ìƒ‰ íƒ€ì…
        hybrid_weights: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        max_steps: ìµœëŒ€ ì‹¤í–‰ ë‹¨ê³„ ìˆ˜
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    agent = PlanExecuteAgent(max_steps=max_steps)
    
    print(f"ğŸš€ Starting Plan and Execute for: {original_query}")
    
    # 1. ì´ˆê¸° ê³„íš ìˆ˜ë¦½
    print("ğŸ“‹ Step 1: Creating initial plan...")
    plan = agent.create_plan(original_query)
    print(f"   Plan created with {len(plan.get('steps', []))} steps")
    print(f"   Goal: {plan.get('overall_goal', 'Not specified')}")
    
    executed_steps = []
    current_step_index = 0
    
    # 2. ê³„íš ì‹¤í–‰ ë£¨í”„
    for iteration in range(max_steps):
        print(f"\nğŸ”„ Iteration {iteration + 1}/{max_steps}")
        
        # í˜„ì¬ ë‹¨ê³„ ì‹¤í–‰
        if current_step_index < len(plan.get('steps', [])):
            current_step = plan['steps'][current_step_index]
            print(f"   Executing planned step {current_step_index + 1}")
            
            step_result = agent.execute_step(current_step, retrieval_type, hybrid_weights)
            executed_steps.append(step_result)
            current_step_index += 1
        
        # ì§„í–‰ ìƒí™© í‰ê°€
        print("   Evaluating progress...")
        evaluation = agent.evaluate_progress(original_query, plan, executed_steps)
        
        decision = evaluation.get('decision', 'CONTINUE')
        print(f"   Decision: {decision}")
        print(f"   Reasoning: {evaluation.get('reasoning', 'No reasoning provided')}")
        
        if decision == "COMPLETE":
            print("   âœ… Problem solving complete!")
            break
        elif decision == "REPLAN":
            print("   ğŸ”„ Replanning...")
            # ì§€ê¸ˆê¹Œì§€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ì¬ê³„íš
            context_so_far = "\n".join([s.get('summary', '') for s in executed_steps])
            plan = agent.create_plan(original_query, context_so_far)
            current_step_index = 0
            print(f"   New plan created with {len(plan.get('steps', []))} steps")
        elif decision == "CONTINUE":
            print("   â¡ï¸ Continuing with execution...")
            # í˜„ì¬ ê³„íšëŒ€ë¡œ ê³„ì† ì§„í–‰
            continue
    
    # 3. ìµœì¢… ë‹µë³€ ìƒì„±
    print("\nğŸ“ Generating final answer...")
    final_answer = agent.generate_final_answer(original_query, executed_steps)
    
    # ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í†µí•©
    all_context_docs = []
    combined_context = []
    
    for step in executed_steps:
        if step.get('context_docs'):
            all_context_docs.extend(step['context_docs'])
        if step.get('context'):
            combined_context.append(f"Step {step['step_number']}: {step['context']}")
    
    combined_context_str = "\n\n".join(combined_context)
    
    print("âœ… Plan and Execute completed successfully")
    
    return {
        "original_query": original_query,
        "plan": plan,
        "executed_steps": executed_steps,
        "final_answer": final_answer,
        "combined_context": combined_context_str,
        "all_context_docs": all_context_docs,
        "total_steps": len(executed_steps)
    }
